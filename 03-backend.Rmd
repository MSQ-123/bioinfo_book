# Backend methods

We describe our backend methods step by step in this chapter. We decided to use java platform as the middle-ware, which integrates SQL query, api testing and json data generation (api exposed to front-end).

## MySQL query

The covid_annot table behind my shiny web is uploaded to MySQL database, total 16 columns (see below). 

Consider that CovidShiny mainly focuses on querying data from the backend, the first thing to improve users experience and start our project is putting the large dataset in csv format in db (previously it was loaded into memory, which is unapplicable to production-grade app).

```{r covid_annot-tab, tidy=FALSE, echo=FALSE}
# covid_annot<- read.csv("_bookdown_files/msq_books_files/dataset/covid_annot.csv", stringsAsFactors = F)

load("./covid_annot.rda")
# knitr::kable(
#   head(covid_annot, 10), booktabs = TRUE,
#   caption = 'A table of the first 10 rows of the mtcars data.'
# )
DT::datatable(head(covid_annot, 10),
                  rownames = FALSE,
                  extensions = "FixedColumns",
                  filter = "bottom",

                  options = list(
                    pageLength = 5,
                    scrollX = TRUE,
                    fixedColumns = list(leftColumns = 1),
                    autoWidth = FALSE,
                    lengthMenu = c(5, 8, 10),
                    columnDefs = list(list(className = "dt-left", target = "_all"))
                  ), escape = FALSE)

```


Note: The dataset uploaded should be checked seriously just in case (some missing rows and *NA* in not-null column). Due to the high frequency of update, incremental id (corresponding to each unique mutation record of virus) column was set. 

Next, I have to mention that the subset function used in my shiny framework can be pretty low-efficient when dealing large dataframe with up to hundreds of thousands rows (since R have to scanning the whole dataframe row by row to find all targets). So the subset syntax should be transformed into SQL query syntax (first in R, for test), for example: 

From: 
```{r r-query, tidy=FALSE, eval=FALSE}
# this example subset by country,M_type (with top frequency),
if(country != "global"){
covid_annot<-covid_annot[covid_annot$country == country, ]
      covid_annot<- covid_annot[covid_annot$M_type %in% names(head(sort(table(covid_annot$M_type),decreasing=TRUE),n=top)),]
}

if(country == "global"){
      covid_annot<- covid_annot[covid_annot$M_type %in% names(head(sort(table(covid_annot$M_type),decreasing=TRUE),n=top)),]
}
```

to: 
```{r sql-query, tidy=FALSE, eval= FALSE}
exec_sql_query_21<-function(conn,args_protein_list,args_country_list,order_M_type){
  if (args_country_list=='global'){  #global without force index, slow
    sql_sentence = glue("select sample, refpos, M_type from covid_annot \
                        where M_type in (select M_type from (select M_type from covid_annot \
                        where protein = '{args_protein_list}' \
                        group by M_type order by count(M_type) DESC LIMIT {order_M_type})as t) \ 
                        and protein = '{args_protein_list}'")
  }
  else{
    sql_sentence = glue("select sample, refpos, M_type from covid_annot FORCE INDEX (country_index)\
                        where M_type in (select M_type from (select M_type from covid_annot \
                        where protein = '{args_protein_list}' and country = '{args_country_list}'\
                        group by M_type order by count(M_type) DESC LIMIT {order_M_type})as t) \ 
                        and protein = '{args_protein_list}' and country = '{args_country_list}'")
  }
  result = dbSendQuery(conn, sql_sentence) # read in 
  result = fetch(result, n = -1) # return dataframe
  return(result)
}

result_global_21<-exec_sql_query_21(my_conn,args_protein_list='S',args_country_list='global',order_M_type='3')
```

SQL sentences need to be optimized, in a few aspects:

+ Use count command to summarize the data feature, such as mutations per sample, frequency of each mutation type, etc. We do this because if we always import a large dataset from MySQL to middle-ware to calculate the statistics, it may run into out of memory.

+ Construct index: We used forced index of country field, to faster M_type sorting (i.e., filter country first, then sort M_type).

+ Divide complex SQL sentence into sub-query, intermediate query results can be preserved in middle-ware (java).

I made several intermediate files for the test of SQL query. With simple modifications, these SQL sentences can be easily translated into java code.  

## SpringBoot in java

The web framework is springboot, and we used swagger for api testing (from my perspective, the api testing is the most powerful part of java application, enabling separation of front-end and back-end. Shiny does not have this function).

```{r swagger-fig, fig.cap='Swagger for best APIs', out.width='80%', fig.asp=.75, fig.align='center', echo = FALSE}

knitr::include_graphics(path = "images/swagger.png")

```


The json data returned by api (simulate GET, POST requests):

```{r api-fig, fig.cap='APIs return json', out.width='80%', fig.asp=.75, fig.align='center', echo = FALSE}

knitr::include_graphics(path = "images/api_json.png")

```

## Merge, annotation algorithm writen in java

The format of snps records output by nucmer script:


```{r nucmer-tab, tidy=FALSE, echo=FALSE}
load("./nucmer.rds")

DT::datatable(head(nucmer, 10),
                  rownames = FALSE,
                  extensions = "FixedColumns",
                  filter = "bottom",

                  options = list(
                    pageLength = 5,
                    scrollX = TRUE,
                    # fixedColumns = list(leftColumns = 1),
                    autoWidth = FALSE,
                    lengthMenu = c(5, 8, 10),
                    columnDefs = list(list(className = "dt-left", target = "_all"))
                  ), escape = FALSE)

```


Each row represents a single mutation record. However, some mutations are contiguous (e.g, 121:C -> T, 122:A -> C, 123:G -> A). Also, contiguous mutations in some cases can be identified as deletions or insertions. For convenience (also save memory, reduce rows in the dataframe), I merged contiguous mutations into single records, rendering merged nucmer data, making it easy to annotate deletion and insertion events.

I followed the code written by other publications[@Mercatelli2020]. I interpreted this tedious code and expressed the core idea to an algorithm engineer.


```{r r-merge, tidy=FALSE, eval=FALSE}
### Merge neighboring events ----
samples<-unique(nucmer$qname)
length(samples) # 12822
pb<-txtProgressBar(0,length(samples),style=3)
for (pbi in 1:length(samples)){ # This will update the nucmer object, deal with each sample records
  sample<-samples[pbi]
  allvars<-nucmer[nucmer$qname==sample,]
  snps<-allvars[(allvars[,"rvar"]!=".")&(allvars[,"qvar"]!="."),]
  inss<-allvars[(allvars[,"rvar"]=="."),]
  dels<-allvars[(allvars[,"qvar"]=="."),]
  # Merge insertions
  prevqpos<-0
  prevrowname<-NULL
  remove<-c()
  i<-1
  corrector<-0
  while(i<=nrow(inss)){
    rpos<-inss[i,"rpos"]
    rvar<-inss[i,"rvar"]
    qvar<-inss[i,"qvar"]
    qpos<-inss[i,"qpos"]
    if((qpos!=1)&(qpos==(prevqpos+1+corrector))){
      inss<-inss[-i,]
      inss[prevrowname,"qvar"]<-paste0(inss[prevrowname,"qvar"],qvar)
      corrector<-corrector+1
      i<-i-1
    } else {
      corrector<-0
      prevrowname<-rownames(inss)[i]
      prevqpos<-qpos
    }
    i<-i+1
  }
  # Merge deletions
  prevqpos<-0
  prevrowname<-NULL
  remove<-c()
  i<-1
  while(i<=nrow(dels)){
    rpos<-dels[i,"rpos"]
    rvar<-dels[i,"rvar"]
    qvar<-dels[i,"qvar"]
    qpos<-dels[i,"qpos"]
    
    if((qpos!=1)&(qpos==(prevqpos))){
      dels<-dels[-i,]
      dels[prevrowname,"rvar"]<-paste0(dels[prevrowname,"rvar"],rvar)
      i<-i-1
    } else {
      prevrowname<-rownames(dels)[i]
      prevqpos<-qpos
    }
    i<-i+1
  }
  # Merge SNPs
  prevqpos<-0
  prevrowname<-NULL
  remove<-c()
  i<-1
  corrector<-0
  while(i<=nrow(snps)){
    rpos<-snps[i,"rpos"]
    rvar<-snps[i,"rvar"]
    qvar<-snps[i,"qvar"]
    qpos<-snps[i,"qpos"]
    
    if((qpos!=1)&(qpos==(prevqpos+1+corrector))){
      snps<-snps[-i,]
      snps[prevrowname,"rvar"]<-paste0(snps[prevrowname,"rvar"],rvar)
      snps[prevrowname,"qvar"]<-paste0(snps[prevrowname,"qvar"],qvar)
      corrector<-corrector+1
      i<-i-1
    } else {
      corrector<-0
      prevrowname<-rownames(snps)[i]
      prevqpos<-qpos
    }
    i<-i+1
  }
  
  # Remerge back
  allvars2<-rbind(snps,inss,dels)
  remove<-setdiff(rownames(allvars),rownames(allvars2))#?setdiff
  nucmer<-nucmer[setdiff(rownames(nucmer),remove),]
  nucmer[rownames(allvars2),]<-allvars2
  setTxtProgressBar(pb,pbi)
}
```

This chunk of code has several problems:

+ Subsetting mutation records of each sample means exhaustive search, which will scan all rows in each for-loop.  When it comes to solve hundreds of thousands rows, this algorithm can be extremely time-consuming.   

```{r r-subset, tidy=FALSE, eval=FALSE}
#This subsets all records of each sample 
allvars<-nucmer[nucmer$qname==sample,]
```

+ Each sample can be processed independently. However, the above code does not involve concurrency. 

To solve these problem, we rewrote the code into java, which supports concurrency easily:

```{java merge}
/**
     * first group and sort records by sample name, mutation type (insertion, deletion, snp), qpos, rpos, so java only needs to merge records in order, without tedious subsetting.
     *
     * @param ses
     * @return
     */
public List<SnpsEntity> mergeQpos(List<SnpsEntity> ses) {
        ses.sort((o1, o2) -> {
            if (!StrUtil.equals(o1.getQ_name(), o2.getQ_name()))
                return StrUtil.compare(o1.getQ_name(), o2.getQ_name(), true);
            if (o1.getType() != o2.getType())
                return Integer.compare(o1.getType().ordinal(), o2.getType().ordinal());
            if (o1.getQ_pos() != o1.getQ_pos())
                return Integer.compare(o1.getQ_pos(), o2.getQ_pos());
            return Integer.compare(o1.getR_pos(), o2.getR_pos());
        });

        List<SnpsEntity> ans = new ArrayList<>();
        for (int i = 0, j; i < ses.size(); i = j) {
            SnpsEntity se = ses.get(i);
            boolean dbg = false;
//             dbg = se.getR_pos() == 28280 && StrUtil.equals(se.getQ_name(),
//                    "hCoV-19/Germany/un-RKI-I-112884/2021|EPI_ISL_1977817|2021-04-23");
            if (dbg)
                System.out.println(se);

            for (j = i + 1; j < ses.size() && ses.get(j - 1).canMerge(ses.get(j)); j++) {
                var sj = ses.get(j);
                if (dbg)
                    System.out.println(sj);

                if (se.getType() == SnpsType.INS)
                    se.setQ_var(se.getQ_var() + sj.getQ_var());
                else if (se.getType() == SnpsType.DEL)
                    se.setR_var(se.getR_var() + sj.getR_var());
                else {
                    se.setR_var(se.getR_var() + sj.getR_var());
                    se.setQ_var(se.getQ_var() + sj.getQ_var());
                }
            }

            ans.add(se);
        }

        ans.sort((o1, o2) -> {
            if (!StrUtil.equals(o1.getQ_name(), o2.getQ_name()))
                return StrUtil.compare(o1.getQ_name(), o2.getQ_name(), true);
            return Integer.compare(o1.getR_pos(), o2.getR_pos());
        });

        return ans;
    }
}

```

In java code, it ordered records first and traversed each record once (without subset function), saving a lot time when dealing with large dataset.

The annotation process in R:

```{r r-annotation, tidy=FALSE, eval=FALSE}
### Provide effect of each SNP and indel ----
#header<-c("sample","refpos","refvar","qvar","qlength","qpos","protein","variant","varclass","annotation")
header<-c("sample","refpos","refvar","qvar","qpos","qlength","protein","variant","varclass","annotation")
results<-matrix(NA,ncol=length(header),nrow=0)
colnames(results)<-header

samples<-unique(nucmer$qname)
pb<-txtProgressBar(0,length(samples),style=3)
for (pbi in 1:length(samples)){ # This will update the nucmer object
  sample<-samples[pbi]
  allvars<-nucmer[nucmer$qname==sample,]
  # Check changes in query protein sequence according to variants
  for(i in 1:nrow(allvars)){ # Assuming they are sorted numerically
    nucline<-allvars[i,]
    rpos<-nucline[1,"rpos"]
    rvar<-nucline[1,"rvar"]
    qvar<-nucline[1,"qvar"]
    qpos<-nucline[1,"qpos"]
    qlength<-nucline[1,"qlength"]
    
    # Match over GFF3 annotation   for each var in a sample: match the var with the GFF3 
    a<-rpos-gff3[,4]
    b<-rpos-gff3[,5]
    signs<-sign(a)*sign(b)
    w<-which(signs==-1)#if signs == -1 then  rpos in GFF anno 
    
    # Outside genes scenarios
    if(length(w)==0){
      if(rpos<gff3[1,4]){    #rpos in the upstream of all gene
        protein<-"5'UTR";output<-c(rpos,"extragenic")
      } else if(rpos>gff3[nrow(gff3),5]){  #?rpos in the downstream of all gene rpos>gff3[nrow(gff3),5]
        protein<-"3'UTR";output<-c(rpos,"extragenic")
      } else {
        protein<-"intergenic";output<-c(rpos,"extragenic")
      }
      
    } else{ # Inside genes scenario
      start<-gff3[w,4]
      end<-gff3[w,5]
      protein<-gff3[w,9]
      refdnaseq<-DNAString(paste0(refseq[start:end],collapse=""))
      refpepseq<-Biostrings::translate(refdnaseq) #obtain protein seq
      refpepseq<-strsplit(as.character(refpepseq),"")[[1]]
      if(qvar=="."){ # Deletion scenario
        if((nchar(rvar)%%3)!=0){ # Deletion frameshift scenario
          mutpos<-round((rpos-start+1)/3)
          output<-c(paste0(refpepseq[mutpos],mutpos),"deletion_frameshift")
        } else { # In-frame deletion
          varseq<-refseq
          varseq<-varseq[-(rpos:(rpos+nchar(rvar)-1))]
          varseq<-varseq[start:(end-nchar(rvar))]
          vardnaseq<-DNAString(paste0(varseq,collapse=""))
          varpepseq<-Biostrings::translate(vardnaseq)
          varpepseq<-strsplit(as.character(varpepseq),"")[[1]]
          
          for(j in 1:length(refpepseq)){
            refj<-refpepseq[j]#
            varj<-varpepseq[j]
            #fix 需要TRUE/FALSE值的地方不可以用缺少值
            if(is.na(refj) | is.na(varj)){
              output<-c(paste0(refj,j),"deletion")
              break()
            }
            if(refj!=varj){
              if(varj=="*"){
                output<-c(paste0(refj,j),"deletion_stop")
              } else {
                output<-c(paste0(refj,j),"deletion")
              }
              break()
            }
          }
        }
      } else if(rvar=="."){ # Insertion scenario
        if((nchar(qvar)%%3)!=0){ # Insertion frameshift scenario
          mutpos<-round((rpos-start+1)/3)
          output<-c(paste0(refpepseq[mutpos],mutpos),"insertion_frameshift")
        } else { # In-frame insertion
          varseq<-c(refseq[1:rpos],strsplit(qvar,"")[[1]],refseq[(rpos+1):length(refseq)])
          varseq<-varseq[start:(end+nchar(qvar))]
          vardnaseq<-DNAString(paste0(varseq,collapse=""))
          varpepseq<-Biostrings::translate(vardnaseq)
          varpepseq<-strsplit(as.character(varpepseq),"")[[1]]
          
          for(j in 1:length(refpepseq)){
            refj<-refpepseq[j]
            varj<-varpepseq[j]
            # fix 值
            if(is.na(refj) | is.na(varj)){
              output<-c(paste0(refj,j),"insertion")
              break()
            }
            if(refj!=varj){
              nr_aa_inserted<-nchar(qvar)/3
              multivarj<-varpepseq[j:(j+nr_aa_inserted-1)]
              if(any(multivarj=="*")){
                multivarj<-paste0(multivarj,collapse="")
                output<-c(paste0(multivarj,j),"insertion_stop")
              } else{
                multivarj<-paste0(multivarj,collapse="")
                output<-c(paste0(multivarj,j),"insertion")
              }
              break()
            }
          }
        }
      } else { # SNP scenario
        if(nchar(qvar)==1){ # ?Single nucleotide scenario 
          varseq<-refseq
          varseq[rpos]<-qvar
          varseq<-varseq[start:end]
          vardnaseq<-DNAString(paste0(varseq,collapse=""))
          varpepseq<-Biostrings::translate(vardnaseq)
          varpepseq<-strsplit(as.character(varpepseq),"")[[1]]
          mutpos<-which(varpepseq!=refpepseq)  #split
          if(length(mutpos)==0){ # Silent SNP scenario
            mutpos<-round((rpos-start+1)/3)
            refaa<-refpepseq[mutpos]
            varaa<-varpepseq[mutpos]
            output<-c(paste0(refaa,mutpos,varaa),"SNP_silent")
          } else { # Changed aa scenario
            refaa<-refpepseq[mutpos]
            varaa<-varpepseq[mutpos]
            if(varaa=="*"){
              output<-c(paste0(refaa,mutpos,varaa),"SNP_stop")
            } else {
              output<-c(paste0(refaa,mutpos,varaa),"SNP")
            }
          }
        } else { # Multiple neighboring nucleotides
          varlength<-nchar(qvar)
          varseq<-refseq
          varseq[rpos:(rpos+varlength-1)]<-strsplit(qvar,"")[[1]]
          varseq<-varseq[start:end]
          vardnaseq<-DNAString(paste0(varseq,collapse=""))
          varpepseq<-Biostrings::translate(vardnaseq)
          varpepseq<-strsplit(as.character(varpepseq),"")[[1]]
          mutpos<-which(varpepseq!=refpepseq)
          if(length(mutpos)==0){ # Silent SNP scenario
            mutpos<-round((rpos-start+1)/3)
            refaa<-refpepseq[mutpos]
            varaa<-varpepseq[mutpos]
            output<-c(paste0(refaa,mutpos,varaa),"SNP_silent")
          } else { # Changed aa scenario
            refaa<-paste0(refpepseq[mutpos],collapse="")
            varaa<-paste0(varpepseq[mutpos],collapse="")
            if(any(varaa=="*")){
              output<-c(paste0(refaa,mutpos[1],varaa),"SNP_stop")
            } else {
              output<-c(paste0(refaa,mutpos[1],varaa),"SNP")
            }
          }
        }
      }
    }
    results<-rbind(results,c(sample,rpos,rvar,qvar,qpos,qlength,protein,output,annot[protein]))
  }
  setTxtProgressBar(pb,pbi)
}
```

I used GFF3 table to search for gene region for each record. To avoid traversing GFF3 each time, we rewrote the traversing part into static index (hash table), in which 1 ~ 30000 genomic coordinates are mapped to gene region and protein group. This index only took up several hundred kilobyte.


In java, `stream()` mode can be switched to `parallel` mode to achieve parallel computing:


```{java annot}
if (mutpos.isEmpty()) {
                            var mp = Math.round((rpos - ge.getStPos() + 1) / 3.0f);
                            mutpos.add(mp);
                            varaa = varPepSeq.getCompoundAt(mp).toString();
                            sae.setVarclass("SNP_silent");
                        } else {
                            varaa = StrUtil.join(StrUtil.EMPTY,
                                    mutpos.stream().map(varPepSeq::getCompoundAt).collect(Collectors.toList()));
                            if (varaa.contains("*"))
                                sae.setVarclass("SNP_STOP");
                            else
                                sae.setVarclass("SNP");
                        }
                        sae.setVariant(
                                StrUtil.join(StrUtil.EMPTY, mutpos.stream().map(refPepSeq::getCompoundAt).collect(Collectors.toList()))
                                        + mutpos.get(0) + varaa);
                    }
/**
     * also use hash table (codon table) to map mutated trinucleotide to amino acid.
     * @return
     */
```

One notable thing is that the division operation can be different between R and java when rewriting code. In R:

```{r r-division, tidy=FALSE, eval=FALSE}
8/3
# [1] 2.666667
```

In java:

```{java divi, tidy=FALSE, eval=FALSE}
8/3
# 2
```

In some cases, this can lead to serious problems. Instead of `8/3`, you should write: `8/3.0`.











